# INF0413 - Processamento Digital de Sinais e Imagens

Equipe: 1

GEOVANA TEIXEIRA CAMARGO - 202303338

JAIR MARTINS SANTIAGO NETO - 202300619

LIDIA RAKEL ALCANTARA DO VALE - 202305743

MIRMILA SOCRATES DO NASCIMENTO - 202306723

NAT√É MILHOMEM LEMOS - 202305744

[üó£ Apresenta√ß√£o](https://drive.google.com/file/d/161ANs8Y8F3Dz1TMrOFk41SCr0QIXG1y-/view?usp=sharing)

[üñ•Ô∏è Slides](https://drive.google.com/file/d/161ANs8Y8F3Dz1TMrOFk41SCr0QIXG1y-/view?usp=sharing)

# Reconhecimento de G√™nero Musical

## I. Introdu√ß√£o

Este trabalho aborda a classifica√ß√£o autom√°tica de m√∫sicas em g√™neros como jazz, rock e pop, utilizando t√©cnicas de processamento digital de sinais e aprendizado de m√°quina. Com o aumento da quantidade de m√∫sicas dispon√≠veis em plataformas de streaming, a categoriza√ß√£o autom√°tica em g√™neros facilita a organiza√ß√£o de bibliotecas, a personaliza√ß√£o de recomenda√ß√µes e a busca em arquivos de √°udio [1]. O objetivo do trabalho √© identificar padr√µes dentre as caracter√≠sticas extra√≠das dos sinais do √°udio, como intensidade de energia e espectro de frequ√™ncia, de forma que possa ser constru√≠do um modelo de reconhecimento musical.

Para isso, foi utilizado como base de dados o GTZAN Music Genre Dataset [2], amplamente reconhecido em pesquisas de classifica√ß√£o de g√™neros musicais, e foi realizada uma revis√£o da literatura sobre extra√ß√£o de caracter√≠sticas e algoritmos de classifica√ß√£o com aprendizado de m√°quina. A metodologia do trabalho inclui a an√°lise de caracter√≠sticas do dataset, pr√©-processamento dos dados e treinamento de modelos de aprendizado. O desempenho dos modelos foi avaliado com as m√©tricas como acur√°cia, matriz de confus√£o e F-score, al√©m de benchmarks da literatura, buscando identificar as abordagens mais eficazes para a classifica√ß√£o de g√™neros musicais.

## II. Fundamentos Te√≥ricos

O reconhecimento de g√™nero musical √© uma tarefa complexa que combina processamento avan√ßado de sinais de √°udio e aprendizado de m√°quina, sendo amplamente aplicado em sistemas de recomenda√ß√£o e organiza√ß√£o de bibliotecas musicais digitais. S√£o abordados conceitos fundamentais que sustentam as t√©cnicas empregadas, detalhando mecanismos, algoritmos e estrat√©gias de avalia√ß√£o.

A biblioteca Librosa desempenha um papel central na an√°lise e visualiza√ß√£o dos sinais de √°udio, permitindo a extra√ß√£o de caracter√≠sticas relevantes, como coeficientes Mel-Frequency Cepstral Coefficients (MFCCs), energia, ritmo e espectrogramas, que servem como base para a classifica√ß√£o de g√™neros musicais [4]. 

Os MFCCs representam a envolt√≥ria espectral de um sinal, capturando o timbre e a tonalidade. Essa t√©cnica √© amplamente reconhecida por seu alinhamento com a percep√ß√£o humana de sons [3]. A an√°lise demonstra que a Transformada Discreta do Cosseno √© adequada para correlacionar espectros tanto de fala quanto de m√∫sica. No processo de extra√ß√£o das caracter√≠sticas MFCC o sinal de √°udio √© segmentado em quadros, aplicando-se uma fun√ß√£o de janela em intervalos regulares. Esse procedimento visa modelar pequenas partes do sinal (geralmente com dura√ß√£o de 20 ms), que s√£o consideradas estatisticamente estacion√°rias. Como resultado, √© gerado um vetor de caracter√≠sticas cepstrais (estruturas peri√≥dicas em espectros de frequ√™ncia) para cada quadro processado.

Os espectrogramas s√£o representa√ß√µes visuais da energia do √°udio em diferentes frequ√™ncias ao longo do tempo. As Redes Neurais Convolucionais (CNNs) s√£o eficazes na tarefa de classifica√ß√£o de √°udios por espectrograma porque podem capturar padr√µes espaciais e temporais, associando caracter√≠sticas espec√≠ficas a g√™neros musicais. O seu uso permite que o modelo aproveite informa√ß√µes detalhadas sobre o timbre, ritmo e frequ√™ncia, fundamentais para diferenciar g√™neros musicais [5]. Essa abordagem melhora a precis√£o na classifica√ß√£o quando comparada a m√©todos baseados apenas em caracter√≠sticas num√©ricas.

Quanto aos m√©todos de aprendizado de m√°quina, o CatBoost √© um algoritmo que tem ganhado popularidade nos √∫ltimos anos, especialmente na √°rea de classifica√ß√£o de g√™neros musicais. O nome "CatBoost" √© uma abrevia√ß√£o de "Category Boosting", o que destaca sua capacidade de lidar eficientemente com vari√°veis categ√≥ricas, um tipo de dado comum nesse tipo de classifica√ß√£o [8]. Pode ser usado para construir modelos que classificam m√∫sicas em diferentes g√™neros com base em suas letras. As letras s√£o processadas e transformadas em caracter√≠sticas num√©ricas que servem de entrada para o algoritmo.  Ap√≥s o treinamento, o modelo pode prever o g√™nero de novas m√∫sicas com base em suas letras.

Outro algoritmo √© o Random Forest, que √© baseado em um conjunto de √°rvores de decis√£o. Ele funciona gerando m√∫ltiplas √°rvores de decis√£o independentes a partir de diferentes amostras aleat√≥rias do conjunto de dados e, em seguida, combina os resultados das √°rvores individuais (por meio de vota√ß√£o, no caso de classifica√ß√£o, ou m√©dia, no caso de regress√£o) para produzir uma previs√£o final. Este m√©todo reduz o risco de overfitting, aproveitando a diversidade entre as √°rvores, e melhora a generaliza√ß√£o do modelo. A inclus√£o de vari√°veis aleat√≥rias na divis√£o de n√≥s das √°rvores tamb√©m aumenta a robustez contra ru√≠do nos dados.

Ainda, O XGBoost (Extreme Gradient Boosting) √© uma t√©cnica de aprendizado baseada no m√©todo de boosting, onde m√∫ltiplas √°rvores de decis√£o s√£o constru√≠das sequencialmente, cada uma tentando corrigir os erros das anteriores. Diferentemente de outros algoritmos de boosting, o XGBoost utiliza otimiza√ß√µes avan√ßadas, como paralelismo e regulariza√ß√£o L1/L2, para melhorar a efici√™ncia computacional e reduzir o risco de overfitting. Ele √© amplamente utilizado em problemas de classifica√ß√£o e regress√£o devido √† sua capacidade de lidar com dados desbalanceados, alta dimensionalidade e cen√°rios complexos.

A avalia√ß√£o de modelos em tarefas de classifica√ß√£o, como a de g√™neros musicais, √© uma etapa essencial para medir sua efic√°cia e identificar √°reas de melhoria. Em problemas de aprendizado de m√°quina, a avalia√ß√£o permite verificar se o modelo treinado √© capaz de generalizar adequadamente para dados desconhecidos, que representam casos reais.
Dentre as m√©tricas comumente utilizadas, a acur√°cia √© uma das mais populares e mede a propor√ß√£o de previs√µes corretas em rela√ß√£o ao total de amostras testadas. Formalmente, √© expressa como a raz√£o entre o n√∫mero de acertos e o n√∫mero total de testes. Embora simples e intuitiva, a acur√°cia pode ser enganosa em conjuntos de dados desbalanceados. Por exemplo, se um g√™nero musical domina o conjunto de dados, o modelo pode obter uma alta acur√°cia apenas por prever consistentemente a classe majorit√°ria, mesmo sem aprender padr√µes significativos das outras classes [6]. 

Por isso, m√©tricas adicionais s√£o frequentemente utilizadas para complementar a an√°lise, como visualiza√ß√µes de desempenho, que podem ser essenciais. Gr√°ficos que mostram a evolu√ß√£o da acur√°cia e do erro para os conjuntos de treinamento e valida√ß√£o s√£o amplamente utilizados. Esses gr√°ficos ajudam a diagnosticar problemas como overfitting (quando o modelo se ajusta excessivamente aos dados de treinamento e perde capacidade de generaliza√ß√£o) e underfitting (quando o modelo √© incapaz de capturar padr√µes significativos nos dados). Por exemplo, uma grande diferen√ßa entre a acur√°cia no treinamento e na valida√ß√£o pode indicar overfitting, enquanto baixos valores de acur√°cia em ambos os conjuntos sugerem underfitting. Esses insights podem orientar ajustes nos hiperpar√¢metros, como o n√∫mero de √°rvores em algoritmos de boosting, a taxa de aprendizado ou mesmo os m√©todos de pr√©-processamento e sele√ß√£o de caracter√≠sticas.

## III. Metodologia

Primeiramente, a base de dados foi composta por trechos de √°udio de 30 segundos, categorizados em 10 diferentes g√™neros musicais. Cada amostra possu√≠a caracter√≠sticas extra√≠das previamente, como coeficientes mel-freq (MFCCs), energia, espectro de frequ√™ncia e tempo entre batidas, que foram fundamentais para representar as propriedades ac√∫sticas dos g√™neros. A manipula√ß√£o dos dados e a realiza√ß√£o das an√°lises explorat√≥rias foram possibilitadas pelas bibliotecas pandas e numpy para organiza√ß√£o e c√°lculos, al√©m de matplotlib e seaborn para visualiza√ß√µes detalhadas.

Na etapa de an√°lise explorat√≥ria, foi verificada a distribui√ß√£o das amostras para cada g√™nero musical utilizando fun√ß√µes como value_counts() do pandas. Foi confirmado o balanceamento da base, ou seja, cada g√™nero possu√≠a a mesma quantidade de amostras (100 amostras por g√™nero). Em seguida, para compreender melhor as caracter√≠sticas dos √°udios, formas de onda e espectrogramas foram gerados com a biblioteca librosa. As formas de onda destacaram a amplitude das amostras ao longo do tempo, enquanto os espectrogramas forneceram uma representa√ß√£o visual da energia em diferentes frequ√™ncias ao longo do tempo, permitindo identificar padr√µes distintos entre os g√™neros. As Figuras 1 e 2 apresentam o gr√°fico de onda e o espectrograma, respectivamente do g√™nero Pop a t√≠tulo de exemplo.

![image](https://github.com/user-attachments/assets/fcfca363-a1c0-4f91-9aae-22e6d241c34d)

Fig. 1  Forma de onda do g√™nero Pop

![image](https://github.com/user-attachments/assets/01acb54e-6b51-4079-b893-4a3eef9880b0)

Fig. 2  Espectrograma  do g√™nero Pop

Ainda na explora√ß√£o dos dados, foi analisada a rela√ß√£o entre as colunas do dataset atrav√©s de em heatmap, apresentado na Figura 3, que representa a correla√ß√£o entre as vari√°veis que capturam caracter√≠sticas m√©dias do √°udio. As cores mais escuras indicam correla√ß√µes fortes (pr√≥ximas de 1 ou -1), enquanto as cores claras representam correla√ß√µes fracas ou inexistentes. Observa-se que os coeficientes MFCC, especialmente os consecutivos, possuem alta correla√ß√£o entre si, o que √© esperado, pois eles descrevem padr√µes relacionados no dom√≠nio da frequ√™ncia. J√° vari√°veis como chroma_stft_mean e zero_crossing_rate_mean mostram menor correla√ß√£o com os MFCCs, sugerindo que capturam aspectos distintos do √°udio, como tonalidade e transi√ß√µes do sinal. Isso pode indicar redund√¢ncia em algumas vari√°veis e complementaridade em outras, o que √© relevante para sele√ß√£o ou redu√ß√£o de features.

![image](https://github.com/user-attachments/assets/64e9db71-03a7-447d-a6de-0ad3f96184a9)
Fig. 3  Heatmap de correla√ß√£o das caracter√≠sticas ac√∫sticas

Em seguida foi realizado o pr√©-processamento dos dados. Inicialmente, as etiquetas de g√™nero foram convertidas em valores num√©ricos utilizando o LabelEncoder da biblioteca scikit-learn, possibilitando o uso das classes como sa√≠da nos algoritmos. Al√©m disso, as caracter√≠sticas num√©ricas foram escaladas com o MinMaxScaler para normaliz√°-las em um intervalo comum, evitando que vari√°veis com amplitudes maiores dominassem o aprendizado. Colunas irrelevantes, como o nome dos arquivos, foram removidas para eliminar dados redundantes e desnecess√°rios. Os dados foram ent√£o divididos em conjuntos de treino (70%) e teste (30%) usando a fun√ß√£o train_test_split, garantindo a valida√ß√£o durante a etapa de treinamento.

Para o treinamento dos modelos, foram escolhidos tr√™s algoritmos com diferentes abordagens de aprendizado supervisionado para classifica√ß√£o: Random Forest, CatBoost, e XGBoost. O Random Forest foi configurado com 1000 √°rvores, profundidade m√°xima de 10, e uma semente aleat√≥ria para reprodutibilidade, sendo eficiente em capturar rela√ß√µes n√£o lineares entre vari√°veis. O CatBoost, otimizado para lidar com vari√°veis categ√≥ricas, foi configurado com uma m√©trica de avalia√ß√£o de acur√°cia e uma fun√ß√£o de perda para classifica√ß√£o multiclasse. J√° o XGBoost, que utiliza boosting para combinar √°rvores de decis√£o, foi configurado com 1000 estimadores e uma taxa de aprendizado de 0,05, ideal para evitar overfitting enquanto constr√≥i √°rvores sequencialmente.

A metodologia tamb√©m incluiu a implementa√ß√£o de uma rede neural utilizando a biblioteca TensorFlow, com uma arquitetura simples, por√©m eficiente. A rede foi definida atrav√©s do modelo sequencial, contendo as seguintes camadas: uma camada de entrada Flatten, que transforma os dados de entrada em uma √∫nica dimens√£o, seguida por uma camada densa (Dense) com 256 neur√¥nios e ativa√ß√£o ReLU. Para melhorar o desempenho e a estabilidade do treinamento, foi adicionada uma camada de normaliza√ß√£o em lote (BatchNormalization). Em seguida, outra camada densa com 128 neur√¥nios e ativa√ß√£o ReLU foi incorporada, acompanhada por uma camada de dropout (Dropout) com taxa de 0,3 para evitar o overfitting. Por fim, a camada de sa√≠da, com 10 neur√¥nios e ativa√ß√£o softmax, foi configurada para realizar a classifica√ß√£o dos g√™neros musicais em categorias exclusivas.

Para cada modelo, foi feita a avalia√ß√£o do seu desempenho com m√©tricas calculadas, que incluem a Acur√°cia, que mede a propor√ß√£o de previs√µes corretas; o F1-Score (Macro), que avalia o equil√≠brio entre precis√£o e revoca√ß√£o para todas as classes de maneira uniforme; e a Precis√£o Top-3, que verifica se a classe correta est√° entre as tr√™s principais previs√µes do modelo. Al√©m disso, foi gerada uma matriz de confus√£o para visualizar como o modelo classificou corretamente ou confundiu as diferentes classes.

## IV. Resultados e Conclus√µes

Os resultados obtidos no trabalho demonstraram o desempenho dos diferentes algoritmos de aprendizado de m√°quina na classifica√ß√£o de g√™neros musicais. Durante os testes, foi poss√≠vel observar que os modelos apresentaram resultados variados, refletindo suas caracter√≠sticas espec√≠ficas e adapta√ß√µes aos dados fornecidos. A Tabela 1 apresenta os resultados obtidos.

Tabela 1  Resultado das m√©tricas de avalia√ß√£o dos modelos

| Modelo             | Acur√°cia | F1-Score (Macro) | Precis√£o Top-3 |
|--------------------|----------|------------------|----------------|
| Random Forest      | 0,78     | 0,78             | 0,96           |
| CatBoost           | 0,83     | 0,83             | 0,96           |
| Gradient Boosting  | 0,78     | 0,78             | 0,96           |
| Rede Neural        | 0,77     | 0,76             | 0,95           |

O algoritmo Random Forest mostrou um bom desempenho geral, alcan√ßando uma acur√°cia de aproximadamente 78%. Isso √© esperado devido √† sua abordagem de combinar m√∫ltiplas √Årvores de Decis√£o, reduzindo o risco de overfitting e aumentando a robustez do modelo. A Figura 4 apresenta a matriz de confus√£o do modelo com Random Forest.

![image](https://github.com/user-attachments/assets/be87110d-d32c-42f3-b889-adecebfc00bd)

Fig. 4  Matriz de confus√£o do Random Forest

O CatBoost, por sua vez, destacou-se como o mais preciso, com uma acur√°cia em torno de 83%, o que evidencia sua efici√™ncia em lidar com dados categ√≥ricos e complexidades inerentes ao conjunto de caracter√≠sticas ac√∫sticas. A Figura 5 apresenta a matriz de confus√£o do modelo com CatBoost.

![image](https://github.com/user-attachments/assets/482f6e44-8c53-4cad-945e-2c4f0e15f4b0)

Fig. 5  Matriz de confus√£o do CatBoost

O Gradient Boosting tamb√©m obteve um desempenho s√≥lido, atingindo cerca de 79%, beneficiando-se de sua abordagem sequencial de otimiza√ß√£o. A Figura 6 apresenta a matriz de confus√£o do modelo com Gradient Boost.

![image](https://github.com/user-attachments/assets/ed66c42d-cf0b-498c-b65e-f6a9ba485981)

Fig. 6  Matriz de confus√£o do Gradient Boost

A rede neural alcan√ßou uma acur√°cia de teste de aproximadamente 77%. Embora inferior ao CatBoost, a rede demonstrou ser promissora para tarefas futuras, considerando sua capacidade de se adaptar a dados maiores ou mais complexos. A Figura 7 apresenta a matriz de confus√£o da rede neural e a Figura 8 apresenta a evolu√ß√£o da acur√°cia e do erro durante o treinamento e o teste do modelo com a rede neural.

![image](https://github.com/user-attachments/assets/0923f99f-7438-4017-8de8-4b350d866f1e)

Fig. 7  Matriz de confus√£o da Rede Neural

![image](https://github.com/user-attachments/assets/bbc4da97-9760-40b9-b50e-48c7f42cd71a)

Fig. 8  Evolu√ß√£o da acur√°cia e do erro a Rede Neural

Os resultados deste trabalho mostram a efic√°cia de t√©cnicas de processamento de sinais e aprendizado de m√°quina na classifica√ß√£o de g√™neros musicais, destacando o CatBoost como o algoritmo mais eficiente, seguido por Random Forest, Gradient Boosting e Rede Neural. A an√°lise de caracter√≠sticas presentes no dataset revelou padr√µes √∫teis para o treinamento de modelos, enquanto a rede neural desenvolvida mostrou potencial para cen√°rios mais complexos. O estudo refor√ßa a import√¢ncia da escolha de caracter√≠sticas e algoritmos, mas aponta limita√ß√µes na base GTZAN devido a inconsist√™ncias entre g√™neros. Futuras pesquisas devem explorar bases mais amplas e arquiteturas avan√ßadas, como CNNs, para melhorias significativas e aplica√ß√µes pr√°ticas na ind√∫stria musical.


## Refer√™ncias

[1] X. Cai e H. Zhang, ‚ÄúMusic genre classification based on auditory image, spectral and acoustic features‚Äù, *Multimedia Syst.*, janeiro de 2022. Acesso em 05/11/2024. Dispon√≠vel: [https://doi.org/10.1007/s00530-021-00886-3](https://doi.org/10.1007/s00530-021-00886-3)  

[2] ‚ÄúGTZAN Dataset - Music Genre Classification‚Äù. *Kaggle: Your Machine Learning and Data Science Community*. Acesso em 05/11/2024. Dispon√≠vel: [https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification/data](https://www.kaggle.com/datasets/andradaolteanu/gtzan-dataset-music-genre-classification/data)

[3] Logan, B. (2000). Mel frequency cepstral coefficients for music modeling. International Symposium on Music Information Retrieval, DOI:https://www.researchgate.net/publication/2552483_Mel_Frequency_Cepstral_Coefficients_for_Music_Modeling

[4] Athulya K., M. & Sindhu, S. "Deep Learning Based Music Genre Classification Using Spectrogram" in Proceedings of the 2nd International Conference on IoT Based Control Networks and Intelligent Systems (ICICNIS 2021), Kerala, India, 2021. DOI: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3883911

[5] G. Tzanetakis, A. Phan, and P. Cook, "A machine learning approach to music genre classification," Electronics Letters, vol. 56, no. 10, pp. 1234-1236, 2019. DOI: 10.1049/el.2019.4202.

[6] N. Ndou, R. Ajoodha, e A. Jadhav, "Music Genre Classification: A Review of Deep-Learning and Traditional Machine-Learning Approaches," em 2021 IEEE International IOT, Electronics and Mechatronics Conference (IEMTRONICS), Toronto, Canad√°, 21-24 de abril de 2021. DOI: https://doi.org/10.1109/IEMTRONICS52119.2021.9422487

[7] SINGH, Y.; BISWAS, A. Robustness of musical features on deep learning models for music genre classification. Expert Systems With Applications, v. 199, p. 116879, 2022. DOI: https://doi.org/10.1016/j.eswa.2022.116879

[8] Salihu, S. A., Lawal, I. O., Abikoye, O. C., Balogun, A. O., Mojeed, H. A., Usman-Hamza, F. E., & Akintola, A. G. (2023). Classification of Music Genres Using Catboost Algorithm. Sule Lamido University Journal of Science and Technology (SLUJST), 7(2), 17‚Äì26. https://doi.org/10.56471/slujst.v7i.472.
